{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90741,"databundleVersionId":10576436,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:04:03.146903Z","iopub.execute_input":"2025-01-17T13:04:03.147289Z","iopub.status.idle":"2025-01-17T13:04:03.154911Z","shell.execute_reply.started":"2025-01-17T13:04:03.147262Z","shell.execute_reply":"2025-01-17T13:04:03.153934Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv\n/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv\n/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/gender_submission.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**Tiền xử lí dữ liệu bị thiếu****","metadata":{}},{"cell_type":"code","source":"Dữ liệu huấn luyện (train.csv) có:\n891 hàng và 12 cột.\nCột Survived là biến mục tiêu (0: không sống sót, 1: sống sót).\nMột số cột có giá trị bị thiếu:\nAge: 714/891 không bị thiếu.\nCabin: chỉ có 204/891 không bị thiếu.\nEmbarked: 889/891 không bị thiếu.\nCác bước tiếp theo:\nTiền xử lý dữ liệu:\n\nXử lý các giá trị bị thiếu (Age, Cabin, Embarked).\nMã hóa các cột phân loại (Sex, Embarked).\nChọn các cột quan trọng làm đặc trưng.\nXây dựng mô hình:\n\nDùng 5 phương pháp được chọn: Logistic Regression, KNN, Decision Tree, Random Forest, Gradient Boosting.\nChạy thực nghiệm và phân tích kết quả:\n\nSo sánh độ chính xác trên tập kiểm tra.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Đọc dữ liệu\ntrain_data = pd.read_csv(\"/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv\")\n\n# Kiểm tra dữ liệu\ntrain_data.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T03:37:38.950707Z","iopub.execute_input":"2025-01-17T03:37:38.951195Z","iopub.status.idle":"2025-01-17T03:37:38.984325Z","shell.execute_reply.started":"2025-01-17T03:37:38.951159Z","shell.execute_reply":"2025-01-17T03:37:38.983049Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# Load the train and test data\ntrain_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv')\ntest_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv')\n\n# Copy data for processing\ntrain_processed = train_data.copy()\ntest_processed = test_data.copy()\n\n# Step 1: Fill missing values\n# Age: Fill missing values with the median\nage_imputer = SimpleImputer(strategy='median')\ntrain_processed['Age'] = age_imputer.fit_transform(train_processed[['Age']])\ntest_processed['Age'] = age_imputer.transform(test_processed[['Age']])\n\n# Embarked: Fill missing values with the most frequent value\nembarked_imputer = SimpleImputer(strategy='most_frequent')\ntrain_processed['Embarked'] = embarked_imputer.fit_transform(train_processed[['Embarked']]).ravel()\ntest_processed['Embarked'] = embarked_imputer.transform(test_processed[['Embarked']]).ravel()\n\n# Fare: Fill missing values with the median (only in test set)\nfare_imputer = SimpleImputer(strategy='median')\ntest_processed['Fare'] = fare_imputer.fit_transform(test_processed[['Fare']])\n\n# Step 2: Encode categorical features (Sex and Embarked)\nencoder = OneHotEncoder(drop='first', sparse_output=False)  # Drop first to avoid multicollinearity\nsex_encoded_train = encoder.fit_transform(train_processed[['Sex']])\nsex_encoded_test = encoder.transform(test_processed[['Sex']])\n\nembarked_encoded_train = encoder.fit_transform(train_processed[['Embarked']])\nembarked_encoded_test = encoder.transform(test_processed[['Embarked']])\n\n# Create DataFrames for encoded features\nsex_encoded_train = pd.DataFrame(sex_encoded_train, columns=['Male'])\nsex_encoded_test = pd.DataFrame(sex_encoded_test, columns=['Male'])\n\nembarked_encoded_train = pd.DataFrame(embarked_encoded_train, columns=['Embarked_Q', 'Embarked_S'])\nembarked_encoded_test = pd.DataFrame(embarked_encoded_test, columns=['Embarked_Q', 'Embarked_S'])\n\n# Step 3: Combine features for training and testing\ntrain_final = pd.concat(\n    [train_processed[['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_train, embarked_encoded_train],\n    axis=1\n)\ntest_final = pd.concat(\n    [test_processed[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_test, embarked_encoded_test],\n    axis=1\n)\n\n# Step 4: Standardize the numerical features\nscaler = StandardScaler()\nnumerical_features_train = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\nnumerical_features_test = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\ntrain_final[numerical_features_train] = scaler.fit_transform(train_final[numerical_features_train])\ntest_final[numerical_features_test] = scaler.transform(test_final[numerical_features_test])\n\nprint(train_final.head())\nprint(test_final.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:04:12.705740Z","iopub.execute_input":"2025-01-17T13:04:12.706171Z","iopub.status.idle":"2025-01-17T13:04:12.773282Z","shell.execute_reply.started":"2025-01-17T13:04:12.706119Z","shell.execute_reply":"2025-01-17T13:04:12.771959Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived    Pclass       Age     SibSp     Parch      Fare  \\\n0            1         0  0.827377 -0.565736  0.432793 -0.473674 -0.502445   \n1            2         1 -1.566107  0.663861  0.432793 -0.473674  0.786845   \n2            3         1  0.827377 -0.258337 -0.474545 -0.473674 -0.488854   \n3            4         1 -1.566107  0.433312  0.432793 -0.473674  0.420730   \n4            5         0  0.827377  0.433312 -0.474545 -0.473674 -0.486337   \n\n   Male  Embarked_Q  Embarked_S  \n0   1.0         0.0         1.0  \n1   0.0         0.0         0.0  \n2   0.0         0.0         1.0  \n3   0.0         0.0         1.0  \n4   1.0         0.0         1.0  \n   PassengerId    Pclass       Age     SibSp     Parch      Fare  Male  \\\n0          892  0.827377  0.394887 -0.474545 -0.473674 -0.490783   1.0   \n1          893  0.827377  1.355510  0.432793 -0.473674 -0.507479   0.0   \n2          894 -0.369365  2.508257 -0.474545 -0.473674 -0.453367   1.0   \n3          895  0.827377 -0.181487 -0.474545 -0.473674 -0.474005   1.0   \n4          896  0.827377 -0.565736  0.432793  0.767630 -0.401017   0.0   \n\n   Embarked_Q  Embarked_S  \n0         1.0         0.0  \n1         0.0         1.0  \n2         1.0         0.0  \n3         0.0         1.0  \n4         0.0         1.0  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**1. Logistic Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Tách dữ liệu huấn luyện và kiểm tra\nX_train = train_final.drop(columns=['PassengerId', 'Survived'])\ny_train = train_final['Survived']\nX_test = test_final.drop(columns=['PassengerId'])\n\n# Huấn luyện mô hình\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n# Dự đoán trên tập kiểm tra\ny_pred = logreg.predict(X_test)\n\n# Đánh giá mô hình\naccuracy = accuracy_score(y_train, logreg.predict(X_train))\nprint(f'Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:34:20.930191Z","iopub.execute_input":"2025-01-17T04:34:20.930809Z","iopub.status.idle":"2025-01-17T04:34:20.979808Z","shell.execute_reply.started":"2025-01-17T04:34:20.930755Z","shell.execute_reply":"2025-01-17T04:34:20.978243Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8002244668911336\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"**2. K-Nearest Neighbors (KNN)**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Huấn luyện mô hình\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# Dự đoán trên tập kiểm tra\ny_pred = knn.predict(X_test)\n\n# Đánh giá mô hình\naccuracy = accuracy_score(y_train, knn.predict(X_train))\nprint(f'Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:35:19.647654Z","iopub.execute_input":"2025-01-17T04:35:19.648096Z","iopub.status.idle":"2025-01-17T04:35:19.746239Z","shell.execute_reply.started":"2025-01-17T04:35:19.648060Z","shell.execute_reply":"2025-01-17T04:35:19.744892Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.856341189674523\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**3. Decision Tree Classifier (CART)**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Huấn luyện mô hình\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\n\n# Dự đoán trên tập kiểm tra\ny_pred = tree.predict(X_test)\n\n# Đánh giá mô hình\naccuracy = accuracy_score(y_train, tree.predict(X_train))\nprint(f'Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:10:54.582818Z","iopub.execute_input":"2025-01-17T13:10:54.583209Z","iopub.status.idle":"2025-01-17T13:10:54.603036Z","shell.execute_reply.started":"2025-01-17T13:10:54.583179Z","shell.execute_reply":"2025-01-17T13:10:54.601196Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9797979797979798\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"**4. Random Forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Huấn luyện mô hình\nforest = RandomForestClassifier(n_estimators=100)\nforest.fit(X_train, y_train)\n\n# Dự đoán trên tập kiểm tra\ny_pred = forest.predict(X_test)\n\n# Đánh giá mô hình\naccuracy = accuracy_score(y_train, forest.predict(X_train))\nprint(f'Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:36:30.136290Z","iopub.execute_input":"2025-01-17T04:36:30.136742Z","iopub.status.idle":"2025-01-17T04:36:30.543534Z","shell.execute_reply.started":"2025-01-17T04:36:30.136703Z","shell.execute_reply":"2025-01-17T04:36:30.542170Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9797979797979798\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"**5. Gradient Boosting (XGBoost)**","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\n\n# Huấn luyện mô hình\nxgb_model = XGBClassifier()\nxgb_model.fit(X_train, y_train)\n\n# Dự đoán trên tập kiểm tra\ny_pred = xgb_model.predict(X_test)\n\n# Đánh giá mô hình\naccuracy = accuracy_score(y_train, xgb_model.predict(X_train))\nprint(f'Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:11:03.476180Z","iopub.execute_input":"2025-01-17T13:11:03.476542Z","iopub.status.idle":"2025-01-17T13:11:03.990244Z","shell.execute_reply.started":"2025-01-17T13:11:03.476515Z","shell.execute_reply":"2025-01-17T13:11:03.988122Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9640852974186308\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"**khác**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Separate features (X) and target (y) from the training dataset\nX = train_final.drop(columns=['PassengerId', 'Survived'])\ny = train_final['Survived']\n\n# Split into training and validation sets (80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T04:39:23.255517Z","iopub.execute_input":"2025-01-17T04:39:23.256215Z","iopub.status.idle":"2025-01-17T04:39:23.277670Z","shell.execute_reply.started":"2025-01-17T04:39:23.256160Z","shell.execute_reply":"2025-01-17T04:39:23.276129Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"((712, 8), (179, 8), (712,), (179,))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Initialize models\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n}\n\n# Train and evaluate each model\nresults = {}\nfor name, model in models.items():\n    # Train the model\n    model.fit(X_train, y_train)\n    # Predict on validation data\n    y_pred = model.predict(X_val)\n    # Calculate accuracy\n    accuracy = accuracy_score(y_val, y_pred)\n    results[name] = accuracy\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:10:34.558308Z","iopub.execute_input":"2025-01-17T13:10:34.558686Z","iopub.status.idle":"2025-01-17T13:10:35.000962Z","shell.execute_reply.started":"2025-01-17T13:10:34.558657Z","shell.execute_reply":"2025-01-17T13:10:34.999840Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Logistic Regression': 0.8044692737430168,\n 'K-Nearest Neighbors': 0.7877094972067039,\n 'Decision Tree': 0.8044692737430168,\n 'Random Forest': 0.8268156424581006,\n 'Gradient Boosting': 0.8044692737430168}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the train and test data\ntrain_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv')\ntest_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv')\n\n# Copy data for processing\ntrain_processed = train_data.copy()\ntest_processed = test_data.copy()\n\n# Step 1: Fill missing values\n# Age: Fill missing values with the median\nage_imputer = SimpleImputer(strategy='median')\ntrain_processed['Age'] = age_imputer.fit_transform(train_processed[['Age']])\ntest_processed['Age'] = age_imputer.transform(test_processed[['Age']])\n\n# Embarked: Fill missing values with the most frequent value\nembarked_imputer = SimpleImputer(strategy='most_frequent')\ntrain_processed['Embarked'] = embarked_imputer.fit_transform(train_processed[['Embarked']]).ravel()\ntest_processed['Embarked'] = embarked_imputer.transform(test_processed[['Embarked']]).ravel()\n\n# Fare: Fill missing values with the median (only in test set)\nfare_imputer = SimpleImputer(strategy='median')\ntest_processed['Fare'] = fare_imputer.fit_transform(test_processed[['Fare']])\n\n# Step 2: Encode categorical features (Sex and Embarked)\nencoder = OneHotEncoder(drop='first', sparse_output=False)  # Drop first to avoid multicollinearity\nsex_encoded_train = encoder.fit_transform(train_processed[['Sex']])\nsex_encoded_test = encoder.transform(test_processed[['Sex']])\n\nembarked_encoded_train = encoder.fit_transform(train_processed[['Embarked']])\nembarked_encoded_test = encoder.transform(test_processed[['Embarked']])\n\n# Create DataFrames for encoded features\nsex_encoded_train = pd.DataFrame(sex_encoded_train, columns=['Male'])\nsex_encoded_test = pd.DataFrame(sex_encoded_test, columns=['Male'])\n\nembarked_encoded_train = pd.DataFrame(embarked_encoded_train, columns=['Embarked_Q', 'Embarked_S'])\nembarked_encoded_test = pd.DataFrame(embarked_encoded_test, columns=['Embarked_Q', 'Embarked_S'])\n\n# Step 3: Combine features for training and testing\ntrain_final = pd.concat(\n    [train_processed[['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_train, embarked_encoded_train],\n    axis=1\n)\ntest_final = pd.concat(\n    [test_processed[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_test, embarked_encoded_test],\n    axis=1\n)\n\n# Step 4: Standardize the numerical features\nscaler = StandardScaler()\nnumerical_features_train = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\nnumerical_features_test = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\ntrain_final[numerical_features_train] = scaler.fit_transform(train_final[numerical_features_train])\ntest_final[numerical_features_test] = scaler.transform(test_final[numerical_features_test])\n\n# Separate features (X) and target (y) from the training dataset\nX_train = train_final.drop(columns=['PassengerId', 'Survived'])\ny_train = train_final['Survived']\nX_test = test_final.drop(columns=['PassengerId'])\n\n# Initialize models\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n}\n\n# Train and evaluate each model on the training data\nresults = {}\nfor name, model in models.items():\n    # Train the model\n    model.fit(X_train, y_train)\n    # Predict on training data to evaluate performance\n    y_pred_train = model.predict(X_train)\n    # Calculate accuracy on training data\n    accuracy_train = accuracy_score(y_train, y_pred_train)\n    results[name] = accuracy_train\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:10:45.637851Z","iopub.execute_input":"2025-01-17T13:10:45.638265Z","iopub.status.idle":"2025-01-17T13:10:46.184136Z","shell.execute_reply.started":"2025-01-17T13:10:45.638234Z","shell.execute_reply":"2025-01-17T13:10:46.183021Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'Logistic Regression': 0.8002244668911336,\n 'K-Nearest Neighbors': 0.856341189674523,\n 'Decision Tree': 0.9797979797979798,\n 'Random Forest': 0.9797979797979798,\n 'Gradient Boosting': 0.8888888888888888}"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Dự đoán","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the train and test data\ntrain_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv')\ntest_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv')\n\n\n# Copy data for processing\ntrain_processed = train_data.copy()\ntest_processed = test_data.copy()\n\n# Step 1: Fill missing values\n# Age: Fill missing values with the median\nage_imputer = SimpleImputer(strategy='median')\ntrain_processed['Age'] = age_imputer.fit_transform(train_processed[['Age']])\ntest_processed['Age'] = age_imputer.transform(test_processed[['Age']])\n\n# Embarked: Fill missing values with the most frequent value\nembarked_imputer = SimpleImputer(strategy='most_frequent')\ntrain_processed['Embarked'] = embarked_imputer.fit_transform(train_processed[['Embarked']]).ravel()\ntest_processed['Embarked'] = embarked_imputer.transform(test_processed[['Embarked']]).ravel()\n\n# Fare: Fill missing values with the median (only in test set)\nfare_imputer = SimpleImputer(strategy='median')\ntest_processed['Fare'] = fare_imputer.fit_transform(test_processed[['Fare']])\n\n# Step 2: Encode categorical features (Sex and Embarked)\nencoder = OneHotEncoder(drop='first', sparse_output=False)  # Drop first to avoid multicollinearity\nsex_encoded_train = encoder.fit_transform(train_processed[['Sex']])\nsex_encoded_test = encoder.transform(test_processed[['Sex']])\n\nembarked_encoded_train = encoder.fit_transform(train_processed[['Embarked']])\nembarked_encoded_test = encoder.transform(test_processed[['Embarked']])\n\n# Create DataFrames for encoded features\nsex_encoded_train = pd.DataFrame(sex_encoded_train, columns=['Male'])\nsex_encoded_test = pd.DataFrame(sex_encoded_test, columns=['Male'])\n\nembarked_encoded_train = pd.DataFrame(embarked_encoded_train, columns=['Embarked_Q', 'Embarked_S'])\nembarked_encoded_test = pd.DataFrame(embarked_encoded_test, columns=['Embarked_Q', 'Embarked_S'])\n\n# Step 3: Combine features for training and testing\ntrain_final = pd.concat(\n    [train_processed[['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_train, embarked_encoded_train],\n    axis=1\n)\ntest_final = pd.concat(\n    [test_processed[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], \n     sex_encoded_test, embarked_encoded_test],\n    axis=1\n)\n\n# Step 4: Standardize the numerical features\nscaler = StandardScaler()\nnumerical_features_train = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\nnumerical_features_test = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\ntrain_final[numerical_features_train] = scaler.fit_transform(train_final[numerical_features_train])\ntest_final[numerical_features_test] = scaler.transform(test_final[numerical_features_test])\n\n# Separate features (X) and target (y) from the training dataset\nX_train = train_final.drop(columns=['PassengerId', 'Survived'])\ny_train = train_final['Survived']\nX_test = test_final.drop(columns=['PassengerId'])\n\n# Initialize models\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n}\n\n# Train and evaluate each model on the training data\nresults = {}\nfor name, model in models.items():\n    # Train the model\n    model.fit(X_train, y_train)\n    # Predict on training data to evaluate performance\n    y_pred_train = model.predict(X_train)\n    # Calculate accuracy on training data\n    accuracy_train = accuracy_score(y_train, y_pred_train)\n    results[name] = accuracy_train\n\n# Dự đoán trên tập kiểm tra (test.csv) và kiểm tra kết quả dự đoán của các mô hình học máy đã huấn luyện.\npredictions = {}\nfor name, model in models.items():\n    y_pred_test = model.predict(X_test)\n    predictions[name] = y_pred_test\n\n# In kết quả dự đoán của các mô hình\nfor name, y_pred_test in predictions.items():\n    print(f\"Predictions for {name}:\")\n    print(y_pred_test[:10])  # In 10 kết quả đầu tiên để kiểm tra\n\nresults, predictions['Logistic Regression'][:10], predictions['K-Nearest Neighbors'][:10], predictions['Decision Tree'][:10], predictions['Random Forest'][:10], predictions['Gradient Boosting'][:10]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T05:19:09.760868Z","iopub.execute_input":"2025-01-17T05:19:09.761588Z","iopub.status.idle":"2025-01-17T05:19:10.403451Z","shell.execute_reply.started":"2025-01-17T05:19:09.761530Z","shell.execute_reply":"2025-01-17T05:19:10.402265Z"}},"outputs":[{"name":"stdout","text":"Predictions for Logistic Regression:\n[0 0 0 0 1 0 1 0 1 0]\nPredictions for K-Nearest Neighbors:\n[0 0 0 1 0 0 1 0 1 0]\nPredictions for Decision Tree:\n[0 0 1 1 1 0 0 0 1 0]\nPredictions for Random Forest:\n[0 0 0 1 0 0 0 0 1 0]\nPredictions for Gradient Boosting:\n[0 0 0 0 0 0 0 0 1 0]\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"({'Logistic Regression': 0.8002244668911336,\n  'K-Nearest Neighbors': 0.856341189674523,\n  'Decision Tree': 0.9797979797979798,\n  'Random Forest': 0.9797979797979798,\n  'Gradient Boosting': 0.8888888888888888},\n array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0]),\n array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0]),\n array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0]),\n array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0]),\n array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]))"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"**File nộp**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Giả sử y_pred là kết quả dự đoán của mô hình trên tập kiểm tra\n# Để minh họa, mình sẽ sử dụng dự đoán từ mô hình Logistic Regression\ny_pred = predictions['Logistic Regression']\n\n# Tạo DataFrame cho file nộp kết quả\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': y_pred\n})\n\n# Lưu file nộp kết quả\nsubmission.to_csv('submission.csv', index=False)\n\n# Tải file về máy tính\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T05:30:56.289153Z","iopub.execute_input":"2025-01-17T05:30:56.289574Z","iopub.status.idle":"2025-01-17T05:30:56.299979Z","shell.execute_reply.started":"2025-01-17T05:30:56.289543Z","shell.execute_reply":"2025-01-17T05:30:56.298877Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"model khác","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the train and test data\ntrain_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/train.csv')\ntest_data = pd.read_csv('/kaggle/input/2024-hk-1-se-355-p-11-titanic-classification/test.csv')\n\n\n# Feature Engineering\ntrain_data['FamilySize'] = train_data['SibSp'] + train_data['Parch']\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch']\ntrain_data['IsAlone'] = (train_data['FamilySize'] == 0).astype(int)\ntest_data['IsAlone'] = (test_data['FamilySize'] == 0).astype(int)\n\n# Fill missing values\nage_imputer = SimpleImputer(strategy='median')\ntrain_data['Age'] = age_imputer.fit_transform(train_data[['Age']])\ntest_data['Age'] = age_imputer.transform(test_data[['Age']])\n\nembarked_imputer = SimpleImputer(strategy='most_frequent')\ntrain_data['Embarked'] = embarked_imputer.fit_transform(train_data[['Embarked']]).ravel()\ntest_data['Embarked'] = embarked_imputer.transform(test_data[['Embarked']]).ravel()\n\nfare_imputer = SimpleImputer(strategy='median')\ntest_data['Fare'] = fare_imputer.fit_transform(test_data[['Fare']])\n\n# Encode categorical features\nencoder = OneHotEncoder(drop='first', sparse_output=False)\nsex_encoded_train = encoder.fit_transform(train_data[['Sex']])\nsex_encoded_test = encoder.transform(test_data[['Sex']])\nembarked_encoded_train = encoder.fit_transform(train_data[['Embarked']])\nembarked_encoded_test = encoder.transform(test_data[['Embarked']])\n\n# Create DataFrames for encoded features\nsex_encoded_train = pd.DataFrame(sex_encoded_train, columns=['Male'])\nsex_encoded_test = pd.DataFrame(sex_encoded_test, columns=['Male'])\nembarked_encoded_train = pd.DataFrame(embarked_encoded_train, columns=['Embarked_Q', 'Embarked_S'])\nembarked_encoded_test = pd.DataFrame(embarked_encoded_test, columns=['Embarked_Q', 'Embarked_S'])\n\n# Combine features for training and testing\ntrain_final = pd.concat(\n    [train_data[['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone']], \n     sex_encoded_train, embarked_encoded_train],\n    axis=1\n)\ntest_final = pd.concat(\n    [test_data[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone']], \n     sex_encoded_test, embarked_encoded_test],\n    axis=1\n)\n\n# Standardize the numerical features\nscaler = StandardScaler()\nnumerical_features_train = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize']\nnumerical_features_test = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize']\n\ntrain_final[numerical_features_train] = scaler.fit_transform(train_final[numerical_features_train])\ntest_final[numerical_features_test] = scaler.transform(test_final[numerical_features_test])\n\n# Separate features (X) and target (y) from the training dataset\nX = train_final.drop(columns=['PassengerId', 'Survived'])\ny = train_final['Survived']\n\n# Split into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Initialize and tune the model\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\nrf = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and model\nbest_rf = grid_search.best_estimator_\n\n# Predict on validation data\ny_pred_val = best_rf.predict(X_val)\naccuracy_val = accuracy_score(y_val, y_pred_val)\nprint(f'Validation Accuracy: {accuracy_val}')\n\n# Predict on test data\ny_pred_test = best_rf.predict(test_final.drop(columns=['PassengerId']))\n\n# Create submission file\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': y_pred_test\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T13:04:58.905822Z","iopub.execute_input":"2025-01-17T13:04:58.906262Z","iopub.status.idle":"2025-01-17T13:06:40.410189Z","shell.execute_reply.started":"2025-01-17T13:04:58.906227Z","shell.execute_reply":"2025-01-17T13:06:40.408882Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 108 candidates, totalling 540 fits\nValidation Accuracy: 0.8044692737430168\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\n# Giả sử y_pred là kết quả dự đoán của mô hình trên tập kiểm tra\n# Để minh họa, mình sẽ sử dụng dự đoán từ mô hình Logistic Regression\ny_pred = predictions['Logistic Regression']\n\n# Tạo DataFrame cho file nộp kết quả\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': y_pred\n})\n\n# Lưu file nộp kết quả\nsubmission.to_csv('submission.csv', index=False)\n\n# Tải file về máy tính\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T05:36:35.126280Z","iopub.execute_input":"2025-01-17T05:36:35.126717Z","iopub.status.idle":"2025-01-17T05:36:35.139071Z","shell.execute_reply.started":"2025-01-17T05:36:35.126682Z","shell.execute_reply":"2025-01-17T05:36:35.137433Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":42}]}